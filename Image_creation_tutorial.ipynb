{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebac9427-6d10-4fb0-972d-c0ae3590d629",
   "metadata": {},
   "source": [
    "## Python code for iceberg detection in SAR data\n",
    "\n",
    "Note that the paths will need to be changed to fit the individual folder structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbb6187-02f3-4e23-bf65-cb77e65011c8",
   "metadata": {},
   "source": [
    "### Step 1: Import Required Python Libraries\r\n",
    "\r\n",
    "In this step, we import all the Python modules necessary for processing and visualizing the SAR and optical imagery.\r\n",
    "\r\n",
    "- `numpy` (`np`): Provides efficient array operations and mathematical functions.  \r\n",
    "- `matplotlib.pyplot` (`plt`): Used for plotting and visualizing images or data.  \r\n",
    "- `sys.exit`: Allows the script to stop execution at a specified point, useful for debugging or partial runs.  \r\n",
    "- `rasterio`: Reads and processes georeferenced raster datasets (GeoTIFF, JP2, etc.).  \r\n",
    "  - `rasterio.plot.show`: Quick visualization of raster images.  \r\n",
    "  - `rasterio.windows.Window` and `from_bounds`: Extract specific sub-regions (windows) from raster files.  \r\n",
    "- `scipy.ndimage`: Provides image processing functions, e.g., uniform filtering for iDPolRAD preprocessing.  \r\n",
    "- `PIL.Image` (`Img`): Handles general image reading and saving.  \r\n",
    "- `itertools`: Supports advanced iteration operations (optional, for loops and combinatorics).  \r\n",
    "- `pandas` (`pd`): Handles tabular data, used here for managing file lists and metadata.  \r\n",
    "- `imageio`: Alternative library for reading/writing images.  \r\n",
    "- `os` and `shutil`: File and directory management.  \r\n",
    "- `cv2` (OpenCV): Optional image processing functions, e.g., resizing or masking.  \r\n",
    "- `tkinter`: Used here to retrieve the system DPI for saving images at a specific size.\r\n",
    "\r\n",
    "> **Tip:** Make sure all libraries are installed (e.g., `pip install rasterio matplotlib pandas imageio opencv-python`) before running the notebook.  \r\n",
    "> `rasterio` may need special installation on some systems; `pip install rasterio` is recommended if `conda` fails.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d308fb5-76c0-4dcb-9fce-a10d239bfb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import these necessary libraries \n",
    "\n",
    "import numpy as np #this is a module that has array functionality \n",
    "import matplotlib.pyplot as plt #graph plotting module\n",
    "from sys import exit #allows you to put an exit() to stop your code in a certain place, good for debugging or only running part of a script\n",
    "import rasterio #rasterio - did it with pip install rasterio - conda didn't seem to work?\n",
    "from rasterio.plot import show\n",
    "from rasterio.windows import Window\n",
    "from rasterio.windows import from_bounds\n",
    "from scipy import ndimage\n",
    "from PIL import Image as Img\n",
    "import itertools\n",
    "import pandas as pd #good for dataframes\n",
    "import imageio\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import tkinter\n",
    "root = tkinter.Tk()\n",
    "my_dpi = root.winfo_fpixels('1i')#this is used for determining dpi in order to save png images to a desired size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188e569c-744e-4c90-b0e3-ee3c17dab6e0",
   "metadata": {},
   "source": [
    "### Step 2: Define Global Variables and Parameters\r\n",
    "\r\n",
    "Before processing the imagery, we set several global variables and hyperparameters:\r\n",
    "\r\n",
    "1. **Input CSV file** (`filenames_df`)  \r\n",
    "   This file contains the file paths for each satellite dataset at every file index, including:\r\n",
    "   - HH-polarized SAR images\r\n",
    "   - HV-polarized SAR images\r\n",
    "   - Optical imagery (JP2 format)\r\n",
    "\r\n",
    "2. **Number of image cutouts per row** (`number_of_images_to_examine_per_row`)  \r\n",
    "   Determines how many sub-images (cutouts) are extracted along one row of the full image.  \r\n",
    "   Total cutouts per image = `(number_of_images_to_examine_per_row)^2`.\r\n",
    "\r\n",
    "3. **Landmask threshold** (`landmask_limit`)  \r\n",
    "   Defines the cutoff between land and water/fast ice in meters.  \r\n",
    "   This threshold is used to remove high-reflectance land features from the analysis. Default = 13 m.\r\n",
    "\r\n",
    "4. **iDPolRAD filter window sizes**  \r\n",
    "   - `trainwindow`: size of the training window (pixels) used to compute the local background average. Must be large enough to capture landscape context but small enough to avoid large-scale variability.  \r\n",
    "     Example: `trainwindow = 57` pixels → 570 m if pixel size = 10 m.\r\n",
    "   - `testwindow`: size of the testing window (pixels) used to compute the local test statistic. Typically corresponds roughly to the expected iceberg size.  \r\n",
    "     Example: `testwindow = 1` pixel → 10 m if pixel size = 10 m.\r\n",
    "\r\n",
    "> **References:** These window sizes follow the optimal parameters found by Soldal et al., 2019 and Marino et al., 2016. Adjusting these values can affect the sensitivity and specificity of the iDPolRAD detection.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab259307-df3c-421d-bbf5-5cb83afb423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables that can be changed.\n",
    "filenames_df=pd.read_csv(r'C:\\Users\\Image_data\\Training\\filenames_test.csv')#csv file containing the pathways for the HH, HV and jp2 image files at each file index.\n",
    "number_of_images_to_examine_per_row=20#this number determines how many cutouts we want to make in one image row, where (number_of_images_to_examine_per_row)**2 is the total number of cutouts produced.\n",
    "landmask_limit=13#Sets the limit between land and sea/fast ice. 13 looks good compared with HH image but could go a bit higher maybe. \n",
    "\n",
    "#You may want to play around with the window values below - read the section in Soldal et al. 2019 and the original paper Marino et al. 2016 \n",
    "#These current values are based on the optimal window values found by Soldal et al. 2019.\n",
    "trainwindow=57#size of the training window - needs to be quite big relative to iceberg but not so big that there is a significant change in landscape within the window. Remember this is in pixels so if they are 10m pixels this will be trainwindow*10m in size\n",
    "testwindow=1#size of test window which should be around the size of an iceberg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c35c3e-1bc9-41a3-acb0-07c5f59b9dd2",
   "metadata": {},
   "source": [
    "### Step 3: Prepare and Verify SAR and Optical Data Files\r\n",
    "\r\n",
    "In this step, we loop over all satellite file indices to set up the corresponding SAR HH, SAR HV, and optical images, as well as the land mask. The script performs the following tasks:\r\n",
    "\r\n",
    "1. **Define file paths** for each data type using the `filenames_df` table:\r\n",
    "   - HH-polarized SAR (`SARimfile_HH_geotiffzoom`)\r\n",
    "   - HV-polarized SAR (`SARimfile_HV_geotiffzoom`)\r\n",
    "   - Optical imagery (`imfile`)\r\n",
    "   - Land mask (`landmask`)\r\n",
    "\r\n",
    "2. **Check that all required files exist** for each file index.  \r\n",
    "   If any file is missing, processing stops for that index.\r\n",
    "\r\n",
    "3. **Keep track of valid indices** in `file_indexes_with_data_list` for which all data exist.\r\n",
    "\r\n",
    "4. **Create output directories** for storing generated images, if they do not already exist.  \r\n",
    "   Each directory is named according to the file index and processing step.\r\n",
    "\r\n",
    "This ensures that only valid datasets are processed and that all outputs are organized systematically.  \r\n",
    "\r\n",
    "> Note: This setup is essential before performing SAR/optical analysis or applying the iDPolRAD filter, because missing files or unorganized outputs can cause downstream errors.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d207414-95a0-4583-9d54-14c84a7c33d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Examine the SAR HH, SAR HV and optical data of each file index.\n",
    "\n",
    "file_indexes_with_data_list=[]#keep track of file indexes with data\n",
    "for file_index in filenames_df['file_index'].tolist():\n",
    "    \n",
    "    #############################################################################################################\n",
    "    #Set up the files\n",
    "    \n",
    "    #below choose which file you want to open\n",
    "    SARimfile_HH_geotiffzoom = f\"{base_dir}/Processed/{filenames_df['HH_file_name'].tolist()[file_index]}\"\n",
    "    SARimfile_HV_geotiffzoom = f\"{base_dir}/Processed/{filenames_df['HV_file_name'].tolist()[file_index]}\"\n",
    "    imfile = f\"{base_dir}/Processed/{filenames_df['jp2_file_name'].tolist()[file_index]}\"\n",
    "    landmask = f\"{base_dir}/Processed/{filenames_df['landmask_file_name'].tolist()[file_index]}\"\n",
    "    \n",
    "    #if Geotiff/jpeg2000/land mask data for one of the satellite data files doesnt exist, stop this script.\n",
    "    if not os.path.isfile(SARimfile_HH_geotiffzoom):\n",
    "        print('+++++++++++++++File index {} has no HH data, stop processing data!+++++++++++++++.'.format(file_index))\n",
    "        break\n",
    "    if not os.path.isfile(SARimfile_HV_geotiffzoom):\n",
    "        print('+++++++++++++++File index {} has no HV data, stop processing data!+++++++++++++++.'.format(file_index))\n",
    "        break\n",
    "    if not os.path.isfile(imfile):\n",
    "        print('+++++++++++++++File index {} has no optical data, stop processing data!+++++++++++++++.'.format(file_index))\n",
    "        break\n",
    "    if not os.path.isfile(landmask):\n",
    "        print('+++++++++++++++File index {} has no land mask data, stop processing data!+++++++++++++++.'.format(file_index))\n",
    "        break\n",
    "        \n",
    "    #add file_index to list if data exists for file index\n",
    "    file_indexes_with_data_list.append(file_index)\n",
    "        \n",
    "    #if an image folder doesnt already exist, then make a folder for storing the produced image files.\n",
    "    if not os.path.exists(r'C:\\Users\\Image_data\\file_index_{}-land_mask'.format(file_index)):\n",
    "        os.makedirs(r'C:\\Users\\Image_data\\file_index_{}-land_mask'.format(file_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36604cce-7be8-404d-9b5f-ee40955d6d53",
   "metadata": {},
   "source": [
    "### Step 4 — Load and Pre-process SAR and Optical Data\n",
    "\n",
    "In this section we load the co-located Sentinel-1 (SAR) and Sentinel-2 (optical) imagery and prepare them for iDPolRAD filtering.\n",
    "\n",
    "What this cell does:\n",
    "\n",
    "### 1. Read optical and SAR files using rasterio\n",
    "We open each image to access:\n",
    "\n",
    "the pixel size (from the affine transform),\n",
    "\n",
    "the geographic bounds,\n",
    "\n",
    "the raw image arrays.\n",
    "\n",
    "### 2. Compute intensity percentiles for optical and SAR data\n",
    "Percentile clipping helps improve contrast and stabilise brightness scaling across scenes.\n",
    "Here we compute:\n",
    "\n",
    "0.15–99.85% percentiles for the optical image,\n",
    "\n",
    "8–93% percentiles for the SAR iDPolRAD output (chosen empirically).\n",
    "\n",
    "3. Extract a matching spatial cutout\n",
    "Because Sentinel-1 and Sentinel-2 tiles differ in size and footprint, we extract a common area using rasterio.windows.from_bounds() so that SAR and optical images align in physical space.\n",
    "\n",
    "### 3. Prepare arrays for iDPolRAD\n",
    "We load the HH and HV SAR channels, then create empty arrays for:\n",
    "\n",
    "the HV and HH training means (large window),\n",
    "\n",
    "the HV testing mean (small window).\n",
    "\n",
    "5. Apply boxcar filters for iDPolRAD\n",
    "The iDPolRAD filter is defined as:\n",
    "\n",
    "### 4. iDPolRAD Filter Equations\r",
    "\r\n",
    "\r\n",
    "The iDPolRAD filter enhances contrast between icebergs and surrounding sea ice by comparing local cross-polarised (HV) backscatter to the surrounding co-polarised (HH) background. The detector is computed as:\r\n",
    "\r\n",
    "$$\r\n",
    "\\Lambda = \\frac{\\langle |HV|^2 \\rangle_\\text{test} - \\langle |HV|^2 \\rangle_\\text{train}}{\\langle |HH|^2 \\rangle_\\text{train}}\r\n",
    "$$\r\n",
    "\r\n",
    "where:  \r\n",
    "\r\n",
    "- $\\langle \\cdot \\rangle_\\text{test}$ is the spatial average over the testing window (small window, e.g., 1×1 pixel),  \r\n",
    "- $\\langle \\cdot \\rangle_\\text{train}$ is the spatial average over the training window (larger window, e.g., 57×57 pixels).\r\n",
    "\r\n",
    "Traditionally, a threshold $T_\\Lambda$ is applied to $\\Lambda$ to detect objects, similar to CFAR detectors. In this work, instead of thresholding, we use the filtered images as input to the CNN, allowing the network to learn features directly from the processed data.\r\n",
    "\r\n",
    "Because $\\Lambda$ is a ratio, some intensity information is lost. To restore the original intensity information, the final iDPolRAD-filtered image is computed as:\r\n",
    "\r\n",
    "$$\r\n",
    "I = \\Lambda \\cdot \\langle |HV|^2 \\rangle_\\text{test}\r\n",
    "$$\r\n",
    "\r\n",
    "Positive values indicate pixels where the HV backscatter is stronger than the local HH background (typical of icebergs), whereas negative values indicate lower HV backscatter than the local HH background (typical of open water patches).\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707337af-86b6-4e50-9f59-911b549cd816",
   "metadata": {},
   "source": [
    "### 5. Cleanup\n",
    "To manage memory efficiently, large intermediate arrays (original SAR tiles, filtered components, etc.) are deleted once no longer needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8dbf23-f182-49d8-83b5-1dec35c3c0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rasterio.open(imfile)#open imfile as defined above in 1.\n",
    "    gt = dataset.transform# this shows the Affine matrix which is the matrix that georeferences the image to the Earth coordinates. \n",
    "    pixelSizeX = gt[0]#pixel size x metres\n",
    "    pixelSizeY =-gt[4]#pixel size y metres\n",
    "    #print('pixel size x metres',pixelSizeX)#comment this out if you want.\n",
    "    #print('pixel size y metres',pixelSizeY)#comment this out if you want.\n",
    "\n",
    "    #show the left, bottom, right and top physical bounds of the full Geotiff/jpeg2000 file. uncomment this if you like.\n",
    "    #print(dataset.bounds)\n",
    "    \n",
    "    #print('uncomment show dataset below if you want to see the whole image but as its large it makes the programme run slowly')\n",
    "    #show(dataset, title='full georeferenced dataset from imfile')#displays the image, comment this out as it makes the programme run slowly as its a big image\n",
    "    \n",
    "    \n",
    "    #determine the 0.15th and 99.8th percentiles for the Optical data from the jpeg2000 image.\n",
    "    with rasterio.open(imfile) as optdataset:\n",
    "        optdataset_full = optdataset.read(1)\n",
    "    optical_percentile_lower = np.percentile(np.concatenate(optdataset_full, axis=0),0.15)\n",
    "    optical_percentile_upper = np.percentile(np.concatenate(optdataset_full, axis=0),99.85)\n",
    "    #delete the full optical dataset that we just loaded in to save memory, since we just finished performing the calculations.\n",
    "    del optdataset_full\n",
    "    \n",
    "    #since the Geotiff image is much larger than the jpeg2000 image, we need to make a cutout of the Geotiff image to match the jpeg2000 image (based on the known physical coordinates in both images).\n",
    "    with rasterio.open(imfile) as dataset_full:\n",
    "        cutout=from_bounds(dataset_full.bounds[0], \n",
    "                           dataset_full.bounds[1], \n",
    "                           dataset_full.bounds[2], \n",
    "                           dataset_full.bounds[3], \n",
    "                           dataset_full.transform)#To cut out in Earth coordinates\n",
    "    \n",
    "    \n",
    "    #determine the 0.15th and 99.8th percentiles for the SAR iDPolRAD data from the Geotiff image.\n",
    "    #Read in HV polarised SAR image from Sentinel 2\n",
    "    with rasterio.open(SARimfile_HV_geotiffzoom) as HVfull:\n",
    "        HVsmall = HVfull.read(1, window=cutout)#same cutout as used above\n",
    "    #Read in HH polarised SAR image from Sentinel 2\n",
    "    with rasterio.open(SARimfile_HH_geotiffzoom) as HHfull:\n",
    "        HHsmall = HHfull.read(1, window=cutout)#same cutout as used above\n",
    "\n",
    "    #below sets up blank arrays the same size as the images above\n",
    "    HVtrain=HVsmall*0.0#i.e. just take the HVsmall array and fill it with zeros\n",
    "    HVtest=HVsmall*0.0\n",
    "    HHtrain=HHsmall*0.0\n",
    "\n",
    "    HHtrain2d=ndimage.uniform_filter(HHsmall**2., size=trainwindow)#takes the HH data squared and convolves it with a mean filter width of trainwindow\n",
    "    HVtrain2d=ndimage.uniform_filter(HVsmall**2., size=trainwindow)#takes the HV data squared and convolves it with a mean filter width of trainwindow\n",
    "    HVtest2d=ndimage.uniform_filter(HVsmall**2., size=testwindow)#takes the HV data squared and convolves it with a mean filter width of testwindow\n",
    "\n",
    "    filtim2d=(HVtest2d-HVtrain2d)/HHtrain2d# this is now formula (1) from Soldal et al. 2019 e.g. the iDPolRAD filter\n",
    "    idpolrad=filtim2d*HVtest2d\n",
    "    \n",
    "    sar_percentile_lower=5.#orig 0.15\n",
    "    sar_percentile_upper=95.#orig 99.85\n",
    "    \n",
    "    \n",
    "    sar_idpolrad_percentile_lower = np.percentile(np.concatenate(idpolrad, axis=0),sar_percentile_lower)\n",
    "    sar_idpolrad_percentile_upper = np.percentile(np.concatenate(idpolrad, axis=0),sar_percentile_upper)\n",
    "    #delete the full SAR iDPolRAD dataset that we just loaded in to save memory, since we just finished performing the calculations.\n",
    "    del HHsmall, HVsmall\n",
    "    del HHtrain, HVtrain, HVtest\n",
    "    del HHtrain2d, HVtrain2d, HVtest2d\n",
    "    del filtim2d\n",
    "    del idpolrad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0288eb-20da-4a09-9af9-e8b8cd98519c",
   "metadata": {},
   "source": [
    "### Step 5: Determine Physical Coordinates for Image Slices\n",
    "\n",
    "Before extracting image cutouts, we calculate the real-world coordinates for each slice based on the full image bounds. This allows us to make spatially accurate slices from both SAR and optical images.\n",
    "\n",
    "1. **Compute Step Size**  \n",
    "   - `x_physical_steps_per_image` and `y_physical_steps_per_image` represent the horizontal and vertical lengths of each image slice.  \n",
    "   - These are determined by dividing the total image width and height (from `dataset.bounds`) by the number of slices per row (`number_of_images_to_examine_per_row`).\n",
    "\n",
    "2. **Generate Slice Corner Coordinates**  \n",
    "   - Bottom-left (`x_physical_coord_list_left_side`, `y_physical_coord_list_left_side`) and top-right (`x_physical_coord_list_right_side`, `y_physical_coord_list_right_side`) coordinates for each slice are calculated using the step sizes.  \n",
    "   - This ensures that each slice corresponds to a distinct, non-overlapping region of the full image.\n",
    "\n",
    "3. **Create Full Combinations**  \n",
    "   - Using `itertools.product`, all possible combinations of x and y coordinates are generated for both bottom-left and top-right corners.  \n",
    "   - This produces lists (`merged_x_physical_coord_list_left_side`, `merged_y_physical_coord_list_left_side`, etc.) that can be directly used to define each slice window in Earth coordinates.\n",
    "\n",
    "These coordinate lists provide a geospatial reference for extracting and saving image cutouts in later steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5648c41b-92f7-4702-9ec0-dd02d4b0bbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the coords for the different image windows\n",
    "\n",
    "    #measure the physical horizontal length of the full Geotiff/jpeg2000 file to determine the size of a horizontal image slice step (based on the global variable).\n",
    "    x_physical_initial = dataset.bounds[0]\n",
    "    x_physical_end = dataset.bounds[2]\n",
    "    x_physical_steps_per_image = (x_physical_end-x_physical_initial)/number_of_images_to_examine_per_row\n",
    "\n",
    "    #measure the physical vertical length of the full Geotiff/jpeg2000 file to determine the size of a vertical image slice step (based on the global variable).\n",
    "    y_physical_initial = dataset.bounds[1]\n",
    "    y_physical_end = dataset.bounds[3]\n",
    "    y_physical_steps_per_image = (y_physical_end-y_physical_initial)/number_of_images_to_examine_per_row\n",
    "\n",
    "    #make lists of the x,y physical coordinates for the bottom left side of each image slice step.\n",
    "    x_physical_coord_list_left_side = []\n",
    "    y_physical_coord_list_left_side = []\n",
    "    for j in range(number_of_images_to_examine_per_row):\n",
    "        x_physical_coord_list_left_side.append(x_physical_initial+(x_physical_steps_per_image*j))\n",
    "        y_physical_coord_list_left_side.append(y_physical_initial+(y_physical_steps_per_image*j))\n",
    "\n",
    "    #make lists of the x,y physical coordinates for the top right side of each image slice step.\n",
    "    x_physical_coord_list_right_side = []\n",
    "    y_physical_coord_list_right_side = []\n",
    "    for j in range(1,number_of_images_to_examine_per_row+1):\n",
    "        x_physical_coord_list_right_side.append(x_physical_initial+(x_physical_steps_per_image*j))\n",
    "        y_physical_coord_list_right_side.append(y_physical_initial+(y_physical_steps_per_image*j))\n",
    "        \n",
    "    #merge the lists of all possible x,y physical coordinates combinations for the bottom left side of each image slice step into one list.\n",
    "    combined_physical_coord_list_left_side = list(itertools.product(x_physical_coord_list_left_side, y_physical_coord_list_left_side))\n",
    "    merged_x_physical_coord_list_left_side = [i[0] for i in combined_physical_coord_list_left_side]\n",
    "    merged_y_physical_coord_list_left_side = [i[1] for i in combined_physical_coord_list_left_side]\n",
    "\n",
    "    #merge the lists of all possible x,y physical coordinates combinations for the top right side of each image slice step into one list.\n",
    "    combined_physical_coord_list_right_side = list(itertools.product(x_physical_coord_list_right_side, y_physical_coord_list_right_side))\n",
    "    merged_x_physical_coord_list_right_side = [i[0] for i in combined_physical_coord_list_right_side]\n",
    "    merged_y_physical_coord_list_right_side = [i[1] for i in combined_physical_coord_list_right_side]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d462510e-a839-43bf-bd7d-c4af2ff8cbae",
   "metadata": {},
   "source": [
    "### Step 6: Extract Georeferenced Cutouts Using Rasterio Windows\r\n",
    "\r\n",
    "To save memory and handle large SAR and optical images efficiently, we extract smaller \"cutouts\" from the full image using `rasterio.windows.from_bounds`.  \r\n",
    "\r\n",
    "**Key steps:**\r\n",
    "\r\n",
    "1. **Check for existing cutouts**  \r\n",
    "   - Before processing, we check whether a PNG output already exists for a slice to avoid redundant computation.\r\n",
    "\r\n",
    "2. **Define the cutout window**  \r\n",
    "   - Using the merged coordinate lists (`merged_x_physical_coord_list_left_side`, etc.), a `from_bounds` window is created for the slice of interest.  \r\n",
    "   - This window corresponds to the exact georeferenced physical coordinates of that slice.\r\n",
    "\r\n",
    "3. **Read only the window**  \r\n",
    "   - `dataset_full.read(1, window=cutout)` reads only the pixels in the window rather than the entire image, saving memory.  \r\n",
    "   - `dataset_full.window_transform(cutout)` retrieves the Affine transform for the cutout, giving the pixel size and enabling georeferenced operations if needed.\r\n",
    "\r\n",
    "4. **Notes on window data**  \r\n",
    "   - The resulting `dataset_w` is a plain 2D NumPy array without georeferencing metadata.  \r\n",
    "   - To visualize or save it as a georeferenced image, we can write it back to a GeoTIFF using the window's transform.\r\n",
    "\r\n",
    "This approach allows us to efficiently process large geospatial datasets while preserving the spatial alignment between SAR and optical images.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d1e2a-4e7b-422c-bdef-e316a5f33962",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a rasterio window that just reads a small cutout of the large image file and therefore saves on memory.\n",
    "\n",
    "    #make an empty list to store the SAR iDPolRAD png image filename from each image slice step.\n",
    "    SAR_iDPolRAD_images_filenames_list = []\n",
    "    #run a for loop to make SAR iDPolRAD and Optical images at each image slice step.\n",
    "    for slice_index in range(number_of_images_to_examine_per_row**2):\n",
    "        \n",
    "        #append the SAR iDPolRAD png image filename (see bottom section of step 7) for each image slice step to a new list.\n",
    "        SAR_iDPolRAD_images_filenames_list.append(r'C:\\Users\\Image_data\\file_index_{0}-land_mask\\SAR_iDPolRAD_image_for_file_index_{0}_for_slice_index_{1}.png'.format(\n",
    "            file_index,slice_index))\n",
    "        \n",
    "        #in case this script crashes, we will have to rerun entire script, this line will ignore images that have already been made.\n",
    "        if os.path.isfile(r'C:\\Users\\Image_data\\file_index_{0}-land_mask\\SAR_iDPolRAD_image_for_file_index_{0}_for_slice_index_{1}.png'.format(file_index,slice_index)):\n",
    "            continue\n",
    "        \n",
    "        #use rasterio and the combined x,y physical coordinates list to obtain a cutout dataset of the Optical image data at each image slice step (based on the matching georeferenced coordinates from the full Geotiff/jpeg2000 data).\n",
    "        with rasterio.open(imfile) as dataset_full:\n",
    "            cutout=from_bounds(merged_x_physical_coord_list_left_side[slice_index], \n",
    "                               merged_y_physical_coord_list_left_side[slice_index], \n",
    "                               merged_x_physical_coord_list_right_side[slice_index], \n",
    "                               merged_y_physical_coord_list_right_side[slice_index], \n",
    "                               dataset_full.transform)#To cut out in Earth coordinates\n",
    "            dataset_w = dataset_full.read(1,window=cutout)#Cut out in georeferenced coordinates - i.e. the bounds are the georeferenced boundaries in metres.\n",
    "            win_transform = dataset_full.window_transform(cutout)#tells you the Affine matrix of the window\n",
    "            #dataset_full is just the same as dataset above but here is not fully read in only the window dataset_w is fully read in so this saves memory\n",
    "\n",
    "        pixelSizeX = win_transform[0]#pixel size of window x metres\n",
    "        pixelSizeY =-win_transform[4]#pixel size of window y metres\n",
    "        #print('pixel size of window x metres',pixelSizeX)#comment this out if you want.\n",
    "        #print('pixel size of window y metres',pixelSizeY)#comment this out if you want.\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783b2baa-adcf-4d1c-8635-1f175783c7ef",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Step 7: Compute the iDPolRAD Filter and Apply Land Mask\n",
    "\n",
    "The iDPolRAD filter (Soldal et al., 2019) enhances icebergs in SAR imagery by comparing the HV and HH polarizations across a small test window and a larger training window. \n",
    "\n",
    "**Key steps:**\n",
    "\n",
    "1. **Read SAR cutouts**  \n",
    "   - Extract the HV and HH polarization data for the current window using `rasterio.read()` with the `window` parameter.  \n",
    "   - The Affine transform of the cutout is also obtained for saving georeferenced outputs.\n",
    "\n",
    "2. **Prepare arrays for filtering**  \n",
    "   - Initialize blank arrays for `HVtest`, `HVtrain`, and `HHtrain`.\n",
    "   - Compute the spatial averages using `ndimage.uniform_filter` over the training and testing windows:\n",
    "     - `trainwindow` is typically large relative to iceberg size (e.g., 57 pixels).  \n",
    "     - `testwindow` corresponds roughly to a single iceberg (e.g., 1 pixel).\n",
    "\n",
    "3. **Compute the iDPolRAD filter**  \n",
    "   \n",
    "   - This enhances features with strong HV scattering relative to the local HH background, highlighting potential icebergs.\n",
    "\n",
    "4. **Save the filtered image**  \n",
    "   - The iDPolRAD image is written as a GeoTIFF to preserve georeferencing for visualization and further processing.\n",
    "\n",
    "5. **Read the optical cutout and land mask**  \n",
    "   - Optical image cutouts are aligned using the same `window` coordinates.  \n",
    "   - The land mask is applied to both SAR and optical images using thresholding, ensuring that land areas are excluded in further analysis.\n",
    "\n",
    "This processing step produces georeferenced, filtered SAR images ready for iceberg detection and comparison with optical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb1946d-701f-4ad9-9031-59cacbeaab21",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Recreate equation (1) from Soldal et al. 2019. This will create an iDPolRAD filter image which enhances the icebergs\n",
    "\n",
    "        #Read in HV polarised SAR image from Sentinel 2\n",
    "        with rasterio.open(SARimfile_HV_geotiffzoom) as HVfull:\n",
    "            HVsmall = HVfull.read(1, window=cutout)#same cutout as used above\n",
    "            HVsmall_transform = HVfull.window_transform(cutout)\n",
    "        #Read in HH polarised SAR image from Sentinel 2\n",
    "        with rasterio.open(SARimfile_HH_geotiffzoom) as HHfull:\n",
    "            HHsmall = HHfull.read(1, window=cutout)#same cutout as used above\n",
    "            HHsmall_transform = HHfull.window_transform(cutout)\n",
    "\n",
    "        #below sets up blank arrays the same size as the images above\n",
    "        HHtrain=HHsmall*0.0#i.e. just take the HVsmall array and fill it with zeros\n",
    "        HVtrain=HVsmall*0.0\n",
    "        HVtest=HVsmall*0.0\n",
    "\n",
    "        HHtrain2d=ndimage.uniform_filter(HHsmall**2., size=trainwindow)#takes the HH data squared and convolves it with a mean filter width of trainwindow\n",
    "        HVtrain2d=ndimage.uniform_filter(HVsmall**2., size=trainwindow)#takes the HV data squared and convolves it with a mean filter width of trainwindow\n",
    "        HVtest2d=ndimage.uniform_filter(HVsmall**2., size=testwindow)#takes the HV data squared and convolves it with a mean filter width of testwindow\n",
    "\n",
    "        filtim2d=(HVtest2d-HVtrain2d)/HHtrain2d# this is now formula (1) from Soldal et al. 2019 e.g. the iDPolRAD filter\n",
    "        idpolrad=filtim2d*HVtest2d\n",
    "\n",
    "        #display the different steps, not georeferenced, comment out if not needed\n",
    "        #show(HVsmall, title='unprocessed SAR HV image')#unprocessed HV image\n",
    "        #show(HHsmall, title='unprocessed SAR HH image')#unprocessed HH image\n",
    "        #show(HHtrain2d, title='SAR HH^2 and convolved with training window')#squared and convolved with mean filter trainwindow\n",
    "        #show(HVtrain2d, title='SAR HV^2 and convolved with training window')#squared and smoothed\n",
    "        #show(HVtest2d, title='SAR HV^2 and convolved with test window')#squared and smoothed\n",
    "        #show(filtim2d, title='SAR iDPolRAD')#iDPolRAD filter\n",
    "\n",
    "        filterfile=r'C:\\Users\\file_index_{0}-land_mask\\Soldal_HHHV_Filter_for_file_index_{0}_for_slice_index_{1}.tiff'.format(\n",
    "            file_index,slice_index)#its probably worth saviing this and just loading it in again as the processing step to do the iDPolRAD filter takes a while.\n",
    "\n",
    "        filterdataset = rasterio.open(filterfile,'w',driver='GTiff',height=idpolrad.shape[0],width=idpolrad.shape[1],count=1,dtype=idpolrad.dtype,crs='EPSG:32640',transform=HVsmall_transform)\n",
    "        #you could use temp.tiff for all of them such that its only one file that keeps being made read in and overwritten rather than lots of files clogging up the directory.\n",
    "        filterdataset.write(idpolrad, 1)\n",
    "        filterdataset.close()\n",
    "        \n",
    "        #now open the file you made as \n",
    "        filterdataset = rasterio.open(filterfile)\n",
    "        filterdataset_w = filterdataset.read(1)\n",
    "\n",
    "        #below just showing the optical image now to show that there's icebergs where the bright spots are in the filtered SAR image\n",
    "        with rasterio.open(imfile) as optdataset:\n",
    "            optdataset_w = optdataset.read(1,window=cutout)#open imfile as a cutout\n",
    "            \n",
    "        \n",
    "        #process the landmask for the image slice step.\n",
    "        with rasterio.open(landmask) as landmask_data:\n",
    "            landmask_data_arr = landmask_data.read(1,window=cutout)#reads channel 1 and turns it into an np.array - i.e. no longer georeferenced\n",
    "        \n",
    "        landmask_data_arr_mask = landmask_data_arr*0.#makes an array the same size as dataset_arr to use as mask\n",
    "\n",
    "        landmask_data_arr_mask[np.where((landmask_data_arr >= landmask_limit) | (landmask_data_arr <= 1.))]=0.#masks land. the or statement about <1 is because there is a region of very low values to bottom right which I think is where data is just missing. \n",
    "        landmask_data_arr_mask[np.where((landmask_data_arr < landmask_limit) & (landmask_data_arr > 1.))]=1\n",
    "        \n",
    "        #add landmask to the SAR image.\n",
    "        filterdataset_w = cv2.bitwise_and(filterdataset_w,filterdataset_w, \n",
    "                                          mask=landmask_data_arr_mask.astype(np.uint8))\n",
    "        \n",
    "        #add landmask to the optical image.\n",
    "        optdataset_w = cv2.bitwise_and(optdataset_w,optdataset_w, \n",
    "                                          mask=landmask_data_arr_mask.astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8895f7fe-69a4-4db5-b88e-15809ab845ed",
   "metadata": {},
   "source": [
    "### Step 8: Generate PNG Images of SAR iDPolRAD and Optical Cutouts\n",
    "\n",
    "After computing the iDPolRAD filtered SAR image and reading the corresponding optical cutout:\n",
    "\n",
    "1. **Compare SAR and Optical images side by side**  \n",
    "   - A combined figure is created using `matplotlib.pyplot.subplots()` with two rows:\n",
    "     - Top: Optical image  \n",
    "     - Bottom: SAR iDPolRAD image  \n",
    "   - Colorbars are added, and percentile-based scaling (`vmin`, `vmax`) is applied to enhance contrast for iceberg detection.  \n",
    "   - The combined figure is saved as a PNG for visual inspection.\n",
    "\n",
    "2. **Create individual PNG images**  \n",
    "   - Optical and SAR iDPolRAD cutouts are saved separately as PNG images.  \n",
    "   - Axes are removed (`plt.axis('off')`) for a clean image.  \n",
    "   - Images are resized to the original cutout dimensions to compensate for cropping from `bbox_inches='tight'`.  \n",
    "   - The images are saved in RGB format to ensure compatibility with image processing pipelines.\n",
    "\n",
    "3. **File naming and organization**  \n",
    "   - Each image slice step is saved with filenames that include:\n",
    "     - `file_index` (the scene index)\n",
    "     - `slice_index` (the cutout step)\n",
    "   - This allows easy tracking and retrieval of specific image slices.\n",
    "\n",
    "This step produces a complete set of preprocessed, visually comparable image cutouts for both SAR and optical data, which will be used for manual inspection, annotation, and eventual CNN training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e7619d-360e-4676-83b3-170f7729258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8Make png images of the cutout SAR iDPolRAD and Optical data cutouts at each image slice step.\n",
    "\n",
    "        #make a combined plot to directly compare icebergs seen in the SAR iDPolRAD and Optical images.\n",
    "        fig, (axColour,axFilter) = plt.subplots(2,1,figsize = (40,30))\n",
    "        im1 = axColour.imshow(optdataset_w, \n",
    "                              vmin=optical_percentile_lower,\n",
    "                              vmax=optical_percentile_upper)#displays the georeferenced optical image\n",
    "        im2 = axFilter.imshow(filterdataset_w,\n",
    "                              vmin=sar_idpolrad_percentile_lower,\n",
    "                              vmax=sar_idpolrad_percentile_upper)#displays the georeferenced iDPolRAD image as in Soldal 2019 Fig 6. b.\n",
    "        axColour.title.set_text('Optical image')\n",
    "        axColour.title.set_fontsize(30)\n",
    "        axFilter.title.set_text('SAR iDPolRAD image')\n",
    "        axFilter.title.set_fontsize(30)\n",
    "        axColour.tick_params(axis='both', which='major', labelsize=20)\n",
    "        axFilter.tick_params(axis='both', which='major', labelsize=20)\n",
    "        cb1 = plt.colorbar(im1, ax=axColour)\n",
    "        cb2 = plt.colorbar(im2, ax=axFilter)\n",
    "        plt.savefig(\n",
    "            r'C:\\Users\\Image_data\\file_index_{0}-land_mask\\SAR_iDPolRAD_and_Optical_image_for_file_index_{0}_for_slice_index_{1}.png'.format(\n",
    "            file_index,slice_index),bbox_inches='tight',facecolor='white', transparent=False)\n",
    "        plt.close()\n",
    "        \n",
    "        #make a png image of the cutout Optical data at current image slice step.\n",
    "        fig, ax = plt.subplots(1,figsize=(len(optdataset_w)/my_dpi, len(optdataset_w)/my_dpi),dpi=my_dpi)\n",
    "        im1 = ax.imshow(optdataset_w,\n",
    "                        vmin=optical_percentile_lower,\n",
    "                        vmax=optical_percentile_upper)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(\n",
    "            r'C:\\Users\\Image_data\\file_index_{0}-land_mask\\Optical_image_for_file_index_{0}_for_slice_index_{1}.png'.format(\n",
    "            file_index,slice_index),bbox_inches='tight',pad_inches=0,dpi=my_dpi)\n",
    "        plt.close()\n",
    "\n",
    "        #resize the png image (we have to resize to original size because bbox_inches crops the white border around the image caused by removing axis in above step but doesnt alter the size of the image back to its original size)\n",
    "        #and save the png image as RGB format rather than RGBA format (which is what plt.savefig() saves it as in the previous step).\n",
    "        img = Img.open(r'C:\\Users\\Image_data\\file_index_{0}-land_mask\\Optical_image_for_file_index_{0}_for_slice_index_{1}.png'.format(\n",
    "            file_index,slice_index))\n",
    "        out = img.resize((len(optdataset_w),len(optdataset_w)))\n",
    "        out.save(r'C:\\Users\\Image_data\\file_index_{0}-land_mask\\Optical_image_for_file_index_{0}_for_slice_index_{1}.png'.format(\n",
    "            file_index,slice_index))\n",
    "        img = Img.open(\n",
    "            r'C:\\Users\\Image_data\\file_index_{0}-land_mask\\Optical_image_for_file_index_{0}_for_slice_index_{1}.png'.format(\n",
    "            file_index,slice_index))\n",
    "        background = Img.new(mode=\"RGB\", size=(len(optdataset_w),len(optdataset_w)), color=(255, 255, 255))\n",
    "        background.paste(img, mask = img.split()[3])\n",
    "        background.save(r'C:\\Users\\Image_data\\file_index_{0}-land_mask\\Optical_image_for_file_index_{0}_for_slice_index_{1}.png'.format(\n",
    "            file_index,slice_index), \"PNG\", quality=100)\n",
    "\n",
    "        \n",
    "        #make a png image of the cutout SAR iDPolRAD data at current image slice step.\n",
    "        fig, ax = plt.subplots(1,figsize=(len(optdataset_w)/my_dpi, len(optdataset_w)/my_dpi),dpi=my_dpi)\n",
    "        im1 = ax.imshow(filterdataset_w,\n",
    "                   vmin=sar_idpolrad_percentile_lower,\n",
    "                   vmax=sar_idpolrad_percentile_upper)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(\n",
    "            r'C:\\Users\\Image_data\\file_index_{0}-land_mask\\SAR_iDPolRAD_image_for_file_index_{0}_for_slice_index_{1}.png'.format(\n",
    "            file_index,slice_index),bbox_inches='tight',pad_inches=0,dpi=my_dpi)\n",
    "        plt.close()\n",
    "\n",
    "        #resize the png image (we have to resize to original size because bbox_inches crops the white border around the image caused by removing axis in above step but doesnt alter the size of the image back to its original size)\n",
    "        #and save the png image as RGB format rather than RGBA format (which is what plt.savefig() saves it as in the previous step).\n",
    "        img = Img.open(r'C:\\Users\\Image_data\\file_index_{0}-land_mask\\SAR_iDPolRAD_image_for_file_index_{0}_for_slice_index_{1}.png'.format(\n",
    "            file_index,slice_index))\n",
    "        out = img.resize((len(optdataset_w),len(optdataset_w)))\n",
    "        out.save(r'C:\\Users\\Image_data\\file_index_{0}-land_mask\\SAR_iDPolRAD_image_for_file_index_{0}_for_slice_index_{1}.png'.format(\n",
    "            file_index,slice_index))\n",
    "        img = Img.open(\n",
    "            r'C:\\Users\\Image_data\\file_index_{0}-land_mask\\SAR_iDPolRAD_image_for_file_index_{0}_for_slice_index_{1}.png'.format(\n",
    "            file_index,slice_index))\n",
    "        background = Img.new(mode=\"RGB\", size=(len(optdataset_w),len(optdataset_w)), color=(255, 255, 255))\n",
    "        background.paste(img, mask = img.split()[3])\n",
    "        background.save(r'C:\\Users\\Image_data\\file_index_{0}-land_mask\\SAR_iDPolRAD_image_for_file_index_{0}_for_slice_index_{1}.png'.format(\n",
    "            file_index,slice_index), \"PNG\", quality=100)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e57ccf5-9843-4820-bff1-7bc87234ff8e",
   "metadata": {},
   "source": [
    "### Step 9: Record Top-Left Coordinates of Each Image Slice\n",
    "\n",
    "Once the SAR iDPolRAD PNG images are generated, we compute the **top-left x and y physical coordinates** for each image slice. These coordinates allow us to:\n",
    "\n",
    "1. Track the **physical location** of each cutout within the full georeferenced image.\n",
    "2. Enable easy conversion between **pixel coordinates** and **real-world coordinates**, which is essential for mapping detected icebergs back to their true positions.\n",
    "\n",
    "Steps performed in this code:\n",
    "\n",
    "- Iterate over all slices in both horizontal and vertical directions to generate top-left coordinate lists.\n",
    "- Combine the image filenames with their corresponding top-left coordinates into a `pandas.DataFrame`.\n",
    "- Save the resulting DataFrame as a CSV file for future reference, ensuring each slice can be linked to its physical location in the original dataset.\n",
    "\n",
    "This structured information is essential for dataset organization, manual inspection, and subsequent CNN training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b67d23-54ab-406a-944c-93d6e36b4008",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Identify the top left x,y physical coordinates in each image slice step.\n",
    "\n",
    "    #Make lists of the top left x,y physical coordinates in each image slice step.\n",
    "    x_physical_coord_list_top_left = []\n",
    "    y_physical_coord_list_top_left = []\n",
    "    for j in range(number_of_images_to_examine_per_row):\n",
    "        for k in range(number_of_images_to_examine_per_row):\n",
    "            x_physical_coord_list_top_left.append(x_physical_coord_list_left_side[j])\n",
    "            y_physical_coord_list_top_left.append(y_physical_coord_list_left_side[k] + y_physical_steps_per_image)   \n",
    "\n",
    "    #Create a dataframe from the lists of the SAR iDPolRAD png image filenames and the top left x,y physical coordinates in each image slice step\n",
    "    combined_physical_coord_df_top_left = pd.DataFrame(data={'filename':SAR_iDPolRAD_images_filenames_list,\n",
    "                                           'x_coord_pixel_top_left_per_image_slice':x_physical_coord_list_top_left,\n",
    "                                           'y_coord_pixel_top_left_per_image_slice':y_physical_coord_list_top_left})\n",
    "    \n",
    "    #save the dataframe to a new file.\n",
    "    combined_physical_coord_df_top_left.to_csv(r'C:\\Users\\Image_data\\combined_physical_coord_df_top_left.csv',\n",
    "                                               index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde30d7c-555e-4754-bb5f-14f5047221c1",
   "metadata": {},
   "source": [
    "### Step 10: Clean Up Temporary Files\r\n",
    "\r\n",
    "After generating the required SAR iDPolRAD and optical image slices for the current file index, temporary files created during processing are no longer needed.  \r\n",
    "\r\n",
    "This step ensures:\r\n",
    "\r\n",
    "- **Disk space is conserved** by removing intermediate files.\r\n",
    "- **Workspace remains organized**, avoiding clutter from temporary TIFF and PNG files.\r\n",
    "- Only the essential processed images and CSVs are retained for future analysis or CNN training.\r\n",
    "\r\n",
    "Specifically, the script deletes:\r\n",
    "\r\n",
    "1. Temporary PNG images used for intermediate visualization.\r\n",
    "2. Temporary TIFF files created for georeferenced cutouts during processing.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5ab389-b4ee-4de0-a771-2616cc0acf84",
   "metadata": {},
   "outputs": [],
   "source": [
    " #9. delete files that are no longer needed which were made as part of this file index.\n",
    "    \n",
    "    #delete the individual temp tiff file as it is no longer needed.\n",
    "    if os.path.exists('..\\Image_data\\file_index_{0}-land_mask\\temp.tiff'.format(file_index)):\n",
    "        os.remove('..\\Image_data\\file_index_{0}-land_mask\\temp.tiff'.format(file_index))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be57e77b-e7a2-4f5f-9349-6b43ba6b990a",
   "metadata": {},
   "source": [
    "### Step 10: Organize Processed Images for Manual Labeling\r\n",
    "\r\n",
    "Once all optical and SAR iDPolRAD image slices have been generated:\r\n",
    "\r\n",
    "1. **Separate folders** are created to store all optical and all SAR images:\r\n",
    "   - `all_optical_images-land_mask_test`\r\n",
    "   - `all_SAR_iDPolRAD_images-land_mask_test`\r\n",
    "\r\n",
    "2. The script **copies the processed images** from each file index subfolder into the respective master folder.  \r\n",
    "\r\n",
    "This organization ensures that:\r\n",
    "\r\n",
    "- Images are **centralized** for easy access during manual iceberg labeling with tools like `labelImg`.\r\n",
    "- File management is simplified, avoiding the need to navigate multiple subfolders.\r\n",
    "- Both optical and SAR images for the same geographic regions are **co-located**, facilitating direct visual comparison.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca116ec4-dc93-4d7f-9d96-19e83e61c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will make copies and transfer all the produced optical and SAR images into these folders.\n",
    "#We will use the images in these folders to compare optical and SAR images during our manual search for icebergs with labelImg.\n",
    "\n",
    "#if a optical image folder doesnt already exist, then make a folder for storing only the produced optical image files.\n",
    "if not os.path.exists(r'C:\\Users\\Image_data\\all_optical_images-land_mask'):\n",
    "    os.makedirs(r'C:\\Users\\Image_data\\all_optical_images-land_mask')\n",
    "#if a SAR image folder doesnt already exist, then make a folder for storing only the produced SAR image files.\n",
    "if not os.path.exists(r'C:\\Users\\Image_data\\all_SAR_iDPolRAD_images-land_mask'):\n",
    "    os.makedirs(r'C:\\Users\\Image_data\\all_SAR_iDPolRAD_images-land_mask')\n",
    "    \n",
    "#put a copy of the produced SAR and optical images into the new optical and SAR image folders.\n",
    "for file_index in filenames_df['file_index'].tolist():\n",
    "    \n",
    "    #only copy images if data exists for the file index\n",
    "    if file_index in file_indexes_with_data_list:\n",
    "    \n",
    "        #transfer all image slices to new folders\n",
    "        for slice_index in range(number_of_images_to_examine_per_row**2):\n",
    "            shutil.copy(r'C:\\Users\\Image_data\\file_index_{0}-land_mask\\Optical_image_for_file_index_{0}_for_slice_index_{1}.png'.format(file_index,slice_index),\n",
    "                        r'C:\\Users\\Image_data\\all_optical_images-land)_mask')\n",
    "            shutil.copy(r'C:\\Users\\Image_data\\file_index_{0}-land_mask\\SAR_iDPolRAD_image_for_file_index_{0}_for_slice_index_{1}.png'.format(file_index,slice_index),\n",
    "                        r'C:\\Users\\Image_data\\all_SAR_iDPolRAD_images-land_mask')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b256f5-678d-4b1e-aa45-62799a3616d1",
   "metadata": {},
   "source": [
    "### Training the YOLOv8 Model\r\n",
    "\r\n",
    "Once the dataset is prepared, training is performed using YOLOv8's `train` function.  \r\n",
    "For this tutorial, we focus on dataset preparation and visualization; the YOLOv8 training step is straightforward and can be executed with the official Ultralytics API.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b8e1b1-956b-4a02-93f6-9e8e2017788d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
